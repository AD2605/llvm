= sycl_ext_oneapi_cluster_group


:source-highlighter: coderay
:coderay-linenums-mode: table


// This section needs to be after the document title.
:doctype: book
:toc2:
:toc: left
:encoding: utf-8
:lang: en
:dpcpp: pass:[DPC++]

// Set the default source code type in this document to C++,
// for syntax highlighting purposes.  This is needed because
// docbook uses c++ and html5 uses cpp.
:language: {basebackend@docbook:c++:cpp}


== Notice

[%hardbreaks]
Copyright (C) 2024-2025 Intel Corporation.  All rights reserved.

Khronos(R) is a registered trademark and SYCL(TM) and SPIR(TM) are trademarks
of The Khronos Group Inc.  OpenCL(TM) is a trademark of Apple Inc. used by
permission by Khronos.


== Contact

To report problems with this extension, please open a new issue at:

https://github.com/intel/llvm/issues


== Dependencies

This extension is written against the SYCL 2020 revision 8 specification.  All
references below to the "core SYCL specification" or to section numbers in the
SYCL specification refer to that revision.


== Status

This is a proposed extension specification, intended to gather community
feedback.  Interfaces defined in this specification may not be implemented yet
or may be in a preliminary state.  The specification itself may also change in
incompatible ways before it is finalized.  *Shipping software products should
not rely on APIs defined in this specification.*


== Overview
Nvidia's compute capability (cc) 9.0 devices introduced a new level in the thread hierarchy, called as thread block clusters, in CUDA terminology. A thread block cluster, is a collection of thread blocks (a workgroup in SYCL terminology), which are guaranteed to be scheduled to be scheduled on a separate compute unit, and are guaranteed to run in parallel, and the thread blocks in the cluster can access each other's shared memory (local memory SYCL terminology). This has various applications, convolutions, GEMMs and FFTs to name a few.

This proposal introduces a SYCL equivalent of the same, to be known as `cluster_group`, and adds the methods to launch a kernel with the cluster size mentioned, accessing the id's of the workgroup in the cluster, and to access another workgroup's local memory within the `cluster_group`.


== Specification
=== Feature test macro

This extension provides a feature-test macro as described in the core SYCL
specification.  An implementation supporting this extension must predefine the
macro `SYCL_EXT_ONEAPI_CLUSTER_GROUP` to one of the values defined in the table
below.  Applications can test for the existence of this macro to determine if
the implementation supports this feature, or applications can test the macro's
value to determine which of the extension's features the implementation
supports.


[%header,cols="1,5"]
|===
|Value
|Description

|1
|The APIs of this experimental extension are not versioned, so the
 feature-test macro always has this value.
|===


=== Launching a kernel with work group clusters

To launch a kernel with a cluster dimension, because of the special scheduling guarantees, the driver requires which kernel will be using the said feature. This introduces an additional parallel_for overload and parallel_for_work_group overloads, accepting cluster dimensions as a `sycl::range`, the dimension of which will be the same as that of the global and the local range.


[source,c++]
----
template<typename KernelName, int Dimensions, typename... Rest>
void parallel_for(nd_range<Dimensions> executionRange, range<Dimensions> clusterGroupRange, Rest&&... rest);

template<int Dimensions>
void parallel_for(nd_range<Dimensions> executionRange, range<Dimensions> clusterGroupRange, const kernel&  
kernelObject);
----

with the defition of `clusterGroupRange` being as follows - 

[%header,cols="1,5"]
|===

|`clusterGroupRange`
|`sycl::range` defining the number of workgroups which form a cluster in each dimension
|===

[NOTE]
====
The total number of workgroups must be a multiple of the cluster range in each dimension.
====

If non-zero cluster dimensions are specified when launching a kernel on non-supported hardware, it should result in a runtime-error.

=== Accessing the Work Group Cluster from within the kernel

Building upon the group heirarchy in SYCL, this proposal another heirachy in the group after `sub_group` and `group` (for workgroups), a class to be called as `cluster_group`, which will  be accessible via the `nd_item` class, via a method to be introduced called `get_cluster_group()`

[%header,cols="10,5"]
|===

|`cluster_group<Dimensions> nd_item::get_cluster_group()`
|Returns the consituent `cluster_group` in the kernel, representing this `cluster_group`'s overall position in the `nd_range`
|===


The `cluster_group` class to have the following methods, to access the various id's 


[%header,cols="5,5"]
|===
|Method
|Description

|`size_t get_group_linear_id(void)`
|Returns the flattened id of the calling `group` within the cluster

|`size_t get_local_linear_id(void)`
|Returns the flattened index of the calling `workitem` within the cluster

|`size_t get_group_linear_range(void)`
|Returns the toal number of `groups` within the cluster

|`size_t get_group_id(size_t)`
|Returns the id of the calling workgroup along the specified dimension

|`size_t get_group_linear_range(size_t)`
|Returns the toal number of `groups` within the cluster in the specified dimension

|`size_t get_local_linear_range(void)`
|Returns the total number of `workItems` within the cluster
|===


To obain the total number of clusters within the group, and getting the cluster id, `nd_item` to have 2 more class methods, namely `get_cluster_range` and `get_cluster_id`

[%header,cols="10,5"]
|===

|`size_t nd_item::get_cluster_range(size_t)`
|Returns the total number of `cluster_group`s in the kernel across the specified dimension

|`size_t nd_item::get_cluster_id(size_t)`
|Returns the id of the cluster across the specified dimension
|===


CC 9.0 devices feature the ability to synchronize all the workgroups within the cluster, and to achieve that in SYCL, this proposes add an overload to the existing `sycl::group_barrier` function, accepting `cluster_group` type.

[%header,cols="10,5"]
|===

|`void sycl::group_barrier(cluster_group<Dimensions> G)`
|Synchronizes all workgroup within the cluster
|===

To prevent un-defined behaviour, in the case where these range's or id's are queried without the cluster dimensions mentioned at launch can be considered as a cluster launch with cluster dimension as 1.

=== Accessing another workgroup's local memory

Workgroup's within the cluster have the ability to access another workgroup's local memory. The local memory addresses can only be addressed by the `workItems` of that workgroup. Therefore, to access another workgroup's local memory, the address would need to be mapped such that it is addressable by calling `workItem` belonging to another workgroup. A public member function of the `cluster_group` class, `get_cluster_local_pointer` will perform the above and return the pointer which can then be dereferenced by the calling `workItem`


[%header,cols="10,5"]
|===

|`T*  get_cluster_local_pointer(T* addr, size_t group_id)`
|Accepts the equivalent address to the memory location relative to the calling `workItem` which is to be mapped from the local memory of the workgroup, as specified by the `group_id`, denoting the flattened `group_id` within the cluster
|===


== Revision History

[cols="5,15,15,70"]
[grid="rows"]
[options="header"]
|========================================
|Rev|Date|Authors|Changes
|1|2024-04-29|Atharva Dubey|*Initial public working draft*
|========================================