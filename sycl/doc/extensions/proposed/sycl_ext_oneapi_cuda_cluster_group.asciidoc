= sycl_ext_oneapi_cuda_cluster_group

:source-highlighter: coderay 
:coderay-linenums-mode: table

// This section needs to be after the document title.
:doctype: book
:toc2:
:toc: left
:encoding: utf-8
:lang: en
:dpcpp: pass:[DPC++]
:endnote: &#8212;{nbsp}end{nbsp}note

// Set the default source code type in this document to C++,
// for syntax highlighting purposes.  This is needed because
// docbook uses c++ and html5 uses cpp.
:language: {basebackend@docbook:c++:cpp}


== Notice

[%hardbreaks] 

Copyright (C) 2024-2024 Intel Corporation.  All rights reserved.

Khronos(R) is a registered trademark and SYCL(TM) and SPIR(TM) are trademarks of
The Khronos Group Inc.  OpenCL(TM) is a trademark of Apple Inc. used by
permission by Khronos.

Other company and product names may be trademarks of the respective companies
with which they are associated and can be claimed as the property of others.

== Contact

To report problems with this extension, please open a new issue at:

https://github.com/intel/llvm/issues


== Dependencies

This extension is written against the SYCL 2020 revision 8 specification.  All
references below to the "core SYCL specification" or to section numbers in the
SYCL specification refer to that revision. 

This extensions also depends on the following other sycl extensions: 

* link:../experimental/sycl_ext_oneapi_enqueue_functions.asciidoc[
          sycl_ext_oneapi_enqueue_functions]
* link:../experimental/sycl/sycl_ext_oneapi_properties.asciidoc[
    sycl_ext_oneapi_properties
]


== Status

This is an experimental extension specification for the `ext_oneapi_cuda`
backend, intended to provide early access to features and gather community
feedback.  
Interfaces defined in this specification are implemented in {dpcpp}, but they
are not finalized and may change incompatibly in future versions of {dpcpp}
without prior notice. *Shipping software products should not rely on APIs
defined in this specification.*

=== Backend support status 

This extension is only supported by the `ext_oneapi_cuda` backend.


== Glossary

* Compute Capability: Abbreviated as "cc", a number assigned to each generation
of NVIDIA's GPUs conveying the feature set associated with that number.



== Overview

NVIDIAâ€™s compute capability (cc) 9.0 devices introduced a new level in the
thread hierarchy, called as thread block clusters, in CUDA terminology. A thread
block cluster, is a collection of thread blocks (a work-group in SYCL
terminology). The work-groups which make up a cluster have the ability to access
each other's local memory, and can be synchronized. This has various
applications, convolutions, GEMMs and FFTs to name a few.

This proposal introduces a SYCL equivalent of the same, to be called as
`cluster_group`, and adds the methods to launch a kernel with a cluster range
and accessing the various id's associated with the cluster
launch in device code.


== Specification

=== Feature test macro

This extension provides a feature-test macro as described in the core SYCL
specification.  An implementation supporting this extension must predefine the
macro `SYCL_EXT_ONEAPI_CUDA_CLUSTER_GROUP` to one of the values defined in the
table below.  Applications can test for the existence of this macro to determine
if the implementation supports this feature, or applications can test the
macro's value to determine which of the extension's features the implementation
supports

[%header,cols="1,5"]
|===
|Value
|Description

|1
|The APIs of this experimental extension are not version-ed, so the
 feature-test macro always has this value.
|===


=== Launching a kernel with a `cluster_group`

Because of the special scheduling guarantees associated with a cluster launch,
the backend must know which kernel would be using this feature. This can be
thought of as a runtime property of the kernel.This proposal defines a new
`struct` which will hold the cluster ranges in each dimension. If the value of
the cluster range is not specified along a dimension, it is assumed to be 1.

[source,c++]
----
namespace sycl::ext::oneapi::experimental::cuda {
struct ClusterRange {
  ClusterRange(size_t x = 1, size_t y = 1, size_t z = 1) : cluster_range({x, y, z}) {}
  size_t operator[](int i) { return cluster_range[i]; }
  sycl::range<3> cluster_range;
};
using ClusterRange_key = ClusterRange;
} // namespace sycl::ext::oneapi::experimental::cuda
----

The property list can the be constructed as follows - 

[source,c++]
----
properties  cluster_launch_property{ClusterRange(1, 2, 1)};
----

Note that the total number of work-groups in the kernel should be a multiple of
the cluster range in each dimension.

The launch functions introduced in `sycl_ext_oneapi_enqueue_functions` can then
be used to launch the kernel with the mentioned properties.


=== Accessing the Cluster Group From Device Code

Building upon the group hierarchy in sycl, this proposal adds another level
above `group`(for work-groups), to be called as `cluster-group`, which 
represents a collection of work-groups and will be accessible via the `nd_item`
class, via a method to be introduced called `ext_oneapi_cuda_get_cluster_group()`.


[%header,cols="10,5"]
|===

|`cluster_group<Dimensions> nd_item::ext_oneapi_cuda_get_cluster_group()`
|Returns the constituent `cluster_group` in the kernel, representing this
`cluster_group`'s overall position in the `nd_range`
|===


The `cluster_group` class will contain the following member functions, to access
the various ids of the work-item and work-groups.

[source,c++]
----
    class cluster_group {
    public:
        using id_type = id<3>;
        using range_type = range<3>;
        using linear_id_type = uint32_t;

        linear_id get_group_linear_id() const;

        linear_id get_local_linear_id() const;

        range_type get_cluster_group_range() const;

        id_type get_group_id() const;
    }
----


[%header,cols="5,5"]
|===
|Method
|Description

|`linear_id get_group_linear_id() const`
|Returns the flattened id of the calling `group` within the cluster

|`linear_id get_local_linear_id() const`
|Returns the flattened index of the calling work-item within the cluster

|`range_type get_cluster_group_range() const`
|Returns the number of work-groups in each dimension

|`id_type get_group_id() const`
|Returns the id of the calling work-group along each dimension
|===


To obtain the total number of clusters in the kernel, and to obtain the 
id of the cluster of the calling work-item, this extension proposes to add two
new member functions the `nd_item` class, namely 
`ext_oneapi_cuda_get_cluster_range` and `ext_oneapi_cuda_get_cluster_id`


[%header,cols="10,5"]
|===

|`range<3> nd_item::ext_oneapi_cuda_get_cluster_range(size_t) const`
|Returns the total number of `cluster_groups` across each dimension.

|`id<3> nd_item::get_cluster_id() const`
|Returns the id of the cluster along each dimension.
|===


To synchronize all the work-groups in a cluster, this extension proposes to 
overload the `sycl::group_barrier` function, accepting the `cluster_group` type


[%header,cols="10,5"]
|===

|`void sycl::group_barrier(cluster_group G)`
|Synchronizes all work-groups within the cluster
|===


== Example

This section adds a representative example of how to launch a kernel with 
the cluster-range specified and accessing various id's within the kernel - 

[source,c++]
----
void kernel_function_foo(nd_item<3> it) {
    using namespace sycl::
    auto cg = it.ext_oneapi_cuda_get_cluster_group();
    auto wg_ids_in_cluster = cg.get_group_id();
    ...
    sycl::group_barrier(cg);
}

sycl::event launch_kernel_with_cluster() {
    using namespace sycl::ext::oneapi::experimental;
    using namespace sycl::ext::oneapi::experimental::cuda;

    sycl::nd_range<3> kernel_range({4096, 4096, 32}, {32, 32, 1});
    properties ClusterProperties(ClusterRange(4, 4, 1));
    sycl::queue queue;
    launch_config config(kernel_range, ClusterProperties);
    return submit_with_event(queue, [&](sycl::handler& cgh){
        nd_launch(cgh, config, kernel_function_foo);
    })
}

----


== Revision History

[cols="5,15,15,70"]
[grid="rows"]
[options="header"]
|========================================
|Rev|Date|Authors|Changes
|1|2024-04-29|Atharva Dubey|*Initial public working draft*
|========================================